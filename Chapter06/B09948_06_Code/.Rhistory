install.packages(c("forecast", "quantmod", "timeSeries", "tseries", "xts"))
library(quantmod)
library(tseries)
library(ggplot2)
library(timeSeries)
library(forecast)
library(xts)
library(keras)
library(tensorflow)
FB <- getSymbols('FB', from='2014-01-01', to='2018-12-31', source = 'google', auto.assign=FALSE)
FB[1:5,]
closing_prices <- FB$FB.Close
plot.xts(closing_prices,main="Facebook Closing Stock Prices")
arima_mod <- auto.arima(closing_prices)
forecasted_prices <- forecast(arima_mod,h=365)
autoplot(forecasted_prices)
fb_future <- getSymbols('FB', from='2019-01-01', to='2019-12-31', source = 'google', auto.assign=FALSE)
future_values <- ts(data = fb_future$FB.Close, start = 1258, end = 1509)
autoplot(forecasted_prices) + autolayer(future_values, series="Actual Closing Prices")
future_prices <- fb_future$FB.Close
closing_deltas <- diff(log(rbind(closing_prices,future_prices)),lag=1)
closing_deltas <- closing_deltas[!is.na(closing_deltas)]
plot(closing_deltas,type='l', main='Facebook Daily Log Returns')
adf.test(closing_deltas)
train_gen <- timeseries_generator(
closing_deltas,
closing_deltas,
length = 3,
sampling_rate = 1,
stride = 1,
start_index = 1,
end_index = 1258,
shuffle = FALSE,
reverse = FALSE,
batch_size = 1
)
test_gen <- timeseries_generator(
closing_deltas,
closing_deltas,
length = 3,
sampling_rate = 1,
stride = 1,
start_index = 1259,
end_index = 1507,
shuffle = FALSE,
reverse = FALSE,
batch_size = 1
)
model <- keras_model_sequential()
model %>%
layer_lstm(units = 4,
input_shape = c(3, 1)) %>%
layer_dense(units = 1)
model %>%
compile(loss = 'mse', optimizer = 'adam')
model
history <- model %>% fit_generator(
train_gen,
epochs = 100,
steps_per_epoch=1,
verbose=2
)
testpredict <- predict_generator(model, test_gen, steps = 200)
trainpredict <- predict_generator(model, train_gen, steps = 1200)
trainpredict <- data.frame(pred = trainpredict)
rownames(trainpredict) <- index(closing_deltas)[4:1203]
trainpredict <- as.xts(trainpredict)
testpredict <- data.frame(pred = testpredict)
rownames(testpredict) <- index(closing_deltas)[1262:1461]
testpredict <- as.xts(testpredict)
closing_deltas$trainpred <- rep(NA,1507)
closing_deltas$trainpred[4:1203] <- trainpredict$pred
closing_deltas$testpred <- rep(NA,1507)
closing_deltas$testpred[1262:1461] <- testpredict$pred
plot(as.zoo(closing_deltas), las=1, plot.type = "single", col = c("light gray","black","black"), lty = c(3,1,1))
evaluate_generator(model, test_gen, steps = 200)
evaluate_generator(model, train_gen, steps = 1200)
train_gen <- timeseries_generator(
closing_deltas,
closing_deltas,
length = 10,
sampling_rate = 1,
stride = 1,
start_index = 1,
end_index = 1258,
shuffle = FALSE,
reverse = FALSE,
batch_size = 1
)
test_gen <- timeseries_generator(
closing_deltas,
closing_deltas,
length = 10,
sampling_rate = 1,
stride = 1,
start_index = 1259,
end_index = 1507,
shuffle = FALSE,
reverse = FALSE,
batch_size = 1
)
model <- keras_model_sequential()
model %>%
layer_lstm(units = 256,input_shape = c(10, 1),return_sequences="True") %>%
layer_dropout(rate = 0.3) %>%
layer_lstm(units = 256,input_shape = c(10, 1),return_sequences="False") %>%
layer_dropout(rate = 0.3) %>%
layer_dense(units = 32, activation = "relu") %>%
layer_dense(units = 1, activation = "linear")
model %>%
compile(
optimizer = optimizer_adam(lr = 0.001),
loss = 'mse',
metrics = 'accuracy')
model
history <- model %>% fit_generator(
train_gen,
epochs = 100,
steps_per_epoch=1,
verbose=2
)
evaluate_generator(model, train_gen, steps = 1200)
evaluate_generator(model, test_gen, steps = 200)
setwd("~/Hands-on-Deep-Learning-with-R-master/B09948_06_Code/B09948_06_Code")
library(keras)
library(tidyverse)
library(knitr)
steamdata <- read_csv("steam-200k.csv", col_names=FALSE)
glimpse(steamdata)
colnames(steamdata) <- c("user", "item", "interaction", "value", "blank")
steamdata <- steamdata %>%
filter(interaction == "play") %>%
select(-blank) %>%
select(-interaction) %>%
mutate(item = str_replace_all(item,'[ [:blank:][:space:] ]',""))
users <- steamdata %>% select(user) %>% distinct() %>% rowid_to_column()
steamdata <- steamdata %>% inner_join(users) %>% rename(userid=rowid)
items <- steamdata %>% select(item) %>% distinct() %>% rowid_to_column()
steamdata <- steamdata %>% inner_join(items) %>% rename(itemid=rowid)
steamdata <- steamdata %>% rename(title=item, rating=value)
n_users <- steamdata %>% select(userid) %>% distinct() %>% nrow()
n_items <- steamdata %>% select(itemid) %>% distinct() %>% nrow()
# normalize data with min-max function
minmax <- function(x) {
return ((x - min(x)) / (max(x) - min(x)))
}
# add scaled rating value
steamdata <- steamdata %>% mutate(rating_scaled = minmax(rating))
# split into training and test
index <- sample(1:nrow(steamdata), 0.8* nrow(steamdata))
train <- steamdata[index,]
test <- steamdata[-index,]
# create matrices of user, items, and ratings for training and test
x_train <- train %>% select(c(userid, itemid)) %>% as.matrix()
y_train <- train %>% select(rating_scaled) %>% as.matrix()
x_test <- test %>% select(c(userid, itemid)) %>% as.matrix()
y_test <- test %>% select(rating_scaled) %>% as.matrix()
library(keras)
library(tidyverse)
library(knitr)
steamdata <- read_csv("steam-200k.csv", col_names=FALSE)
glimpse(steamdata)
colnames(steamdata) <- c("user", "item", "interaction", "value", "blank")
steamdata <- steamdata %>%
filter(interaction == "play") %>%
select(-blank) %>%
select(-interaction) %>%
mutate(item = str_replace_all(item,'[ [:blank:][:space:] ]',""))
users <- steamdata %>% select(user) %>% distinct() %>% rowid_to_column()
steamdata <- steamdata %>% inner_join(users) %>% rename(userid=rowid)
items <- steamdata %>% select(item) %>% distinct() %>% rowid_to_column()
steamdata <- steamdata %>% inner_join(items) %>% rename(itemid=rowid)
steamdata <- steamdata %>% rename(title=item)
n_users <- steamdata %>% select(userid) %>% distinct() %>% nrow()
n_items <- steamdata %>% select(itemid) %>% distinct() %>% nrow()
# normalize data with min-max function
minmax <- function(a) {
return ((a - min(a)) / (max(a) - min(a)))
}
# add scaled rating value
steamdata <- steamdata %>% mutate(rating_scaled = minmax(value))
# split into training and test
index <- sample(1:nrow(steamdata), 0.8* nrow(steamdata))
train <- steamdata[index,]
test <- steamdata[-index,]
# create matrices of user, items, and ratings for training and test
x_train <- train %>% select(c(userid, itemid)) %>% as.matrix()
y_train <- train %>% select(rating_scaled) %>% as.matrix()
x_test <- test %>% select(c(userid, itemid)) %>% as.matrix()
y_test <- test %>% select(rating_scaled) %>% as.matrix()
